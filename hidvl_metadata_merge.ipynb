{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIDVL metadata spreadsheet merge script\n",
    "As part of the process to generate draft HIDVL MARC records by batch, we need to combine metadata spreadsheets from two different sources: the legacy metadata submission form (the data from which is converted via another script from a text file to a CSV file) and the new Airtable metadata submission form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, time\n",
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime(\"%Y-%m-%d_%I-%M_%p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy metadata\n",
    "In the first part of this process, we'll deal with the legacy metadata that dates prior to 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter file name and if appropriate filepath of legacy metadata csv:  /Users/alexandra/Downloads/hidvl_dmd_parsed_combined_2019-11-22_05-09_PM_March2022_pre-2019.csv\n"
     ]
    }
   ],
   "source": [
    "pre_2019_dmd = input(\"enter file name and if appropriate filepath of legacy metadata csv: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load old metadata dataframe from csv\n",
    "df_pre_2019_dmd = pd.read_csv(pre_2019_dmd,na_filter=False,quotechar = '\"')\n",
    "#print(df_pre_2019_dmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex replaces whitespace at the end of the cells with NaN; this also has the effect of flipping \"blank\" cells to NaN\n",
    "#I'm sure there is a more elegant way to do this.\n",
    "df_pre_2019_dmd = df_pre_2019_dmd.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify new column names for the incoming metadata column headers\n",
    "pre_2019_dmd_newcols = {\n",
    "    \"HI_number\" : \"HI\",\n",
    "    \"ï»¿NOID\": \"NOID\",\n",
    "    \"Cataloged Status\" : \"Cataloged_Status\",\n",
    "    \"Publication Cycle\" : \"Publication_Cycle\",\n",
    "    \"Correction_note\" : \"Correction_Note\",\n",
    "    \"Mastering Offset Timecode\": \"Mastering_Offset_Timecode\",\n",
    "    \"Language\": \"Language_Note\",\n",
    "    \"Subjects\" : \"Subjects_653\",\n",
    "    \"Participants\" : \"Participants_old\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#rename the column headers\n",
    "df_pre_2019_dmd.rename(columns=pre_2019_dmd_newcols, inplace=True)\n",
    "#print(\"new df\",df_pre_2019_dmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an empty column for 650 subjects\n",
    "#based on https://stackoverflow.com/questions/16327055/how-to-add-an-empty-column-to-a-dataframe\n",
    "df_pre_2019_dmd[\"Subjects_650\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#strip the period from the end of the production credits and participants fields\n",
    "#based on https://stackoverflow.com/questions/37001787/remove-ends-of-string-entries-in-pandas-dataframe-column\n",
    "df_pre_2019_dmd[\"Additional_Production_Credits\"] = df_pre_2019_dmd[\"Additional_Production_Credits\"].str.rstrip('.')\n",
    "df_pre_2019_dmd[\"Participants_old\"] = df_pre_2019_dmd[\"Participants_old\"].str.rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Roland Marconi, editor; Melody Bates, Marco Ce...\n",
      "1    Roland Marconi, editor; Melody Bates, Marco Ce...\n",
      "2    Roland Marconi, editor; Melody Bates, Marco Ce...\n",
      "Name: Participants, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 3 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q7/pr_v50794r9g526wvnc601rw0000gn/T/ipykernel_31592/3596225731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pre_2019_dmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Participants\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#print a sample row to check that concatenation worked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pre_2019_dmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Participants'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3771\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3773\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3775\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "#concatenate all of the participant, additional production credits, and performer columns.\n",
    "#the catch is that sometimes these columns are empty!\n",
    "#based on https://stackoverflow.com/questions/60724940/concatenate-strings-across-columns-that-are-not-null\n",
    "df_pre_2019_dmd[\"Participants\"] = df_pre_2019_dmd[[\"Additional_Production_Credits\", \"Participants_old\", \"Performers\"]].apply(lambda x: '; '.join(x.dropna()), axis=1)\n",
    "#print the participants field\n",
    "print(df_pre_2019_dmd[\"Participants\"])\n",
    "#print a sample row to check that concatenation worked\n",
    "print(df_pre_2019_dmd.loc[3,'Participants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   HI                         3 non-null      object \n",
      " 1   NOID                       3 non-null      object \n",
      " 2   Cataloged_Status           0 non-null      object \n",
      " 3   Publication_Cycle          0 non-null      object \n",
      " 4   Correction_Note            3 non-null      object \n",
      " 5   Format                     3 non-null      object \n",
      " 6   Source_Tape_Generation     3 non-null      object \n",
      " 7   Mastering_Offset_Timecode  0 non-null      object \n",
      " 8   Run_Time                   3 non-null      object \n",
      " 9   Series_Title               3 non-null      object \n",
      " 10  Meeting_Information        0 non-null      object \n",
      " 11  Title                      3 non-null      object \n",
      " 12  Alternate_Titles           3 non-null      object \n",
      " 13  Date_of_Production         3 non-null      object \n",
      " 14  Location_Venue             3 non-null      object \n",
      " 15  Language_Note              3 non-null      object \n",
      " 16  Main_Production_Credits    3 non-null      object \n",
      " 17  Worktypes                  3 non-null      object \n",
      " 18  Performance_Genres         3 non-null      object \n",
      " 19  Summary                    3 non-null      object \n",
      " 20  Subjects_653               3 non-null      object \n",
      " 21  Rights_Holder              3 non-null      object \n",
      " 22  Broadcast_Note             0 non-null      object \n",
      " 23  Note_to_Cataloger          0 non-null      object \n",
      " 24  Pattern                    3 non-null      int64  \n",
      " 25  Subjects_650               0 non-null      float64\n",
      " 26  Participants               3 non-null      object \n",
      "dtypes: float64(1), int64(1), object(25)\n",
      "memory usage: 776.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#get rid of the extra columns that we just concatenated into the new participants field\n",
    "df_pre_2019_dmd.drop([\"Additional_Production_Credits\",\"Participants_old\",\"Performers\"], axis=1, inplace=True)\n",
    "#get some info about the dataframe\n",
    "print(df_pre_2019_dmd.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airtable metadata\n",
    "In the second part of this process, we'll deal with the new metadata that dates from 2020 to the present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter file name and if appropriate filepath of airtable metadata csv:  /Users/alexandra/Downloads/Metadata-March_2022.csv\n"
     ]
    }
   ],
   "source": [
    "post_2019_dmd = input(\"enter file name and if appropriate filepath of airtable metadata csv: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load new metadata dataframe from csv\n",
    "df_post_2019_dmd = pd.read_csv(post_2019_dmd,na_filter=False,quotechar = '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_2019_dmd = df_post_2019_dmd.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_post_2019_dmd = df_post_2019_dmd.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify new column names for the incoming metadata column headers\n",
    "post_2019_dmd_newcols = {\n",
    "    \"HI #\" : \"HI\",\n",
    "    \"Inventory\": \"NOID\",\n",
    "    \"Publication cycle\" : \"Publication_Cycle\",\n",
    "    \"Date of event\" : \"Date_of_Production\",\n",
    "    \"Location information\": \"Location_Venue\",\n",
    "    \"Language note\": \"Language_Note\",\n",
    "    \"Language\": \"Language_List\",\n",
    "    \"Main production credits\": \"Main_Production_Credits\",\n",
    "    \"Event type\" : \"Worktypes\",\n",
    "    \"Subject\": \"Subjects_653\",\n",
    "    \"Copyright holder\": \"Rights_Holder\",\n",
    "    \"Artist bio\": \"Artist_Bio\",\n",
    "    \"Run time rounded\":\"Run_Time\",\n",
    "    \"Collection\": \"Series_Title\",\n",
    "    \"Conference\":\"Meeting_Information\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27 entries, 0 to 26\n",
      "Data columns (total 36 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   HI                                 27 non-null     object \n",
      " 1   NOID                               27 non-null     object \n",
      " 2   DMD Finalized                      27 non-null     object \n",
      " 3   Title                              27 non-null     object \n",
      " 4   Alternate title 1                  1 non-null      object \n",
      " 5   Alternate title 2                  0 non-null      float64\n",
      " 6   Alternate title 3                  0 non-null      float64\n",
      " 7   Alternate title 4                  0 non-null      float64\n",
      " 8   Alternate title 5                  0 non-null      float64\n",
      " 9   Series_Title                       27 non-null     object \n",
      " 10  Meeting_Information                1 non-null      object \n",
      " 11  Worktypes                          27 non-null     object \n",
      " 12  Date_of_Production                 27 non-null     object \n",
      " 13  Location_Venue                     27 non-null     object \n",
      " 14  Subjects_653                       27 non-null     object \n",
      " 15  Summary                            27 non-null     object \n",
      " 16  Artist_Bio                         27 non-null     object \n",
      " 17  Rights_Holder                      27 non-null     object \n",
      " 18  Main_Production_Credits            27 non-null     object \n",
      " 19  Participants                       27 non-null     object \n",
      " 20  Run time                           27 non-null     object \n",
      " 21  Run_Time                           27 non-null     object \n",
      " 22  Source media format                27 non-null     object \n",
      " 23  How many source media form items?  27 non-null     int64  \n",
      " 24  Language_List                      27 non-null     object \n",
      " 25  Language_Note                      0 non-null      float64\n",
      " 26  Publication_Cycle                  27 non-null     object \n",
      " 27  Copyright contact designation      17 non-null     object \n",
      " 28  Copyright address                  10 non-null     object \n",
      " 29  Copyright business phone           10 non-null     object \n",
      " 30  Copyright mobile phone             0 non-null      float64\n",
      " 31  Copyright fax                      10 non-null     object \n",
      " 32  Copyright email 1                  27 non-null     object \n",
      " 33  Copyright email 2                  0 non-null      float64\n",
      " 34  Copyright email 3                  0 non-null      float64\n",
      " 35  Copyright website                  27 non-null     object \n",
      "dtypes: float64(8), int64(1), object(27)\n",
      "memory usage: 7.7+ KB\n",
      "new df None\n"
     ]
    }
   ],
   "source": [
    "#rename the column headers\n",
    "df_post_2019_dmd.rename(columns=post_2019_dmd_newcols, inplace=True)\n",
    "#see what columns we have in the dataframe now:\n",
    "#print(\"new df\",df_post_2019_dmd)\n",
    "print(\"new df\",df_post_2019_dmd.info())\n",
    "#Alternate titles have imported as non-null float64 values, and I'm not sure why!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an empty column for 650 subjects\n",
    "#based on https://stackoverflow.com/questions/16327055/how-to-add-an-empty-column-to-a-dataframe\n",
    "df_post_2019_dmd[\"Subjects_650\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do some concatenation to populate the format field\n",
    "df_post_2019_dmd [\"Format\"] = df_post_2019_dmd[\"How many source media form items?\"].astype(str) + \" \" + df_post_2019_dmd[\"Source media format\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "1     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "2     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "3     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "4     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "5     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "6     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "7     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "8     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "9     20 Cooper Square, Fifth Floor, New York, NY 10...\n",
      "10    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "11    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "12    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "13    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "14    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "15    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "16    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "17    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "18    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "19    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "20    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "21    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "22    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "23    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "24    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "25    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "26    Pedro Bennaton, pedrobennaton@errogrupo.com.br...\n",
      "Name: Copyright_Contact, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#combine copyright holder contact info into a single field\n",
    "#based on https://stackoverflow.com/questions/60724940/concatenate-strings-across-columns-that-are-not-null\n",
    "df_post_2019_dmd[\"Copyright_Contact\"] = df_post_2019_dmd[[\"Copyright contact designation\",\"Copyright address\",\"Copyright business phone\",\"Copyright mobile phone\",\"Copyright fax\",\"Copyright email 1\",\"Copyright email 2\",\"Copyright email 3\",\"Copyright website\"]].apply(lambda x: ', '.join(x.dropna()), axis=1)\n",
    "df_post_2019_dmd[\"Copyright_Contact\"] = df_post_2019_dmd[\"Copyright_Contact\"].replace('\\\\n', ', ', regex=True)\n",
    "print(df_post_2019_dmd[\"Copyright_Contact\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#combine alternate titles into a single cell\n",
    "#based on https://stackoverflow.com/questions/60724940/concatenate-strings-across-columns-that-are-not-null\n",
    "#this may not actually concatenate any alternate titles, because there is usually only ever one\n",
    "df_post_2019_dmd[\"Alternate_Titles\"] = df_post_2019_dmd[[\"Alternate title 1\",\"Alternate title 2\",\"Alternate title 3\",\"Alternate title 4\",\"Alternate title 5\"]].apply(lambda x: '|'.join(x.dropna()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     \n",
       "12                                                     \n",
       "13    (ERUPTION: Seedling Depends on the Size of the...\n",
       "14                                                     \n",
       "15                                                     \n",
       "16                                                     \n",
       "17                                                     \n",
       "18                                                     \n",
       "19                                                     \n",
       "20                                                     \n",
       "21                                                     \n",
       "22                                                     \n",
       "23                                                     \n",
       "24                                                     \n",
       "25                                                     \n",
       "26                                                     \n",
       "Name: Alternate_Titles, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tried filling the blank cells in this field with np.nan but it didn't work...\n",
    "df_post_2019_dmd[\"Alternate_Titles\"].fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "19    False\n",
      "20    False\n",
      "21    False\n",
      "22    False\n",
      "23    False\n",
      "24    False\n",
      "25    False\n",
      "26    False\n",
      "Name: Alternate_Titles, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#I still wanted to check to see if the values had become null values!\n",
    "print(df_post_2019_dmd [\"Alternate_Titles\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#get rid of any newline characters\n",
    "df_post_2019_dmd[\"Alternate_Titles\"] = df_post_2019_dmd[\"Alternate_Titles\"].replace('\\\\n', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#print a sample record that had newlines\n",
    "print(df_post_2019_dmd.loc[3,\"Alternate_Titles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#drop unwanted columns and see what remains\n",
    "df_post_2019_dmd.drop([\"Run time\",\"DMD Finalized\",\"How many source media form items?\",\"Source media format\",\"Alternate title 1\",\"Alternate title 2\",\"Alternate title 3\",\"Alternate title 4\",\"Alternate title 5\",\"Copyright contact designation\",\"Copyright address\",\"Copyright business phone\",\"Copyright mobile phone\",\"Copyright fax\",\"Copyright email 1\",\"Copyright email 2\",\"Copyright email 3\",\"Copyright website\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27 entries, 0 to 26\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   HI                       27 non-null     object \n",
      " 1   NOID                     27 non-null     object \n",
      " 2   Title                    27 non-null     object \n",
      " 3   Series_Title             27 non-null     object \n",
      " 4   Meeting_Information      1 non-null      object \n",
      " 5   Worktypes                27 non-null     object \n",
      " 6   Date_of_Production       27 non-null     object \n",
      " 7   Location_Venue           27 non-null     object \n",
      " 8   Subjects_653             27 non-null     object \n",
      " 9   Summary                  27 non-null     object \n",
      " 10  Artist_Bio               27 non-null     object \n",
      " 11  Rights_Holder            27 non-null     object \n",
      " 12  Main_Production_Credits  27 non-null     object \n",
      " 13  Participants             27 non-null     object \n",
      " 14  Run_Time                 27 non-null     object \n",
      " 15  Language_List            27 non-null     object \n",
      " 16  Language_Note            0 non-null      float64\n",
      " 17  Publication_Cycle        27 non-null     object \n",
      " 18  Subjects_650             0 non-null      float64\n",
      " 19  Format                   27 non-null     object \n",
      " 20  Copyright_Contact        27 non-null     object \n",
      " 21  Alternate_Titles         27 non-null     object \n",
      "dtypes: float64(2), object(20)\n",
      "memory usage: 4.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_post_2019_dmd.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 30 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   HI                         30 non-null     object \n",
      " 1   NOID                       30 non-null     object \n",
      " 2   Cataloged_Status           0 non-null      object \n",
      " 3   Publication_Cycle          27 non-null     object \n",
      " 4   Correction_Note            3 non-null      object \n",
      " 5   Format                     30 non-null     object \n",
      " 6   Source_Tape_Generation     3 non-null      object \n",
      " 7   Mastering_Offset_Timecode  0 non-null      object \n",
      " 8   Run_Time                   30 non-null     object \n",
      " 9   Series_Title               30 non-null     object \n",
      " 10  Meeting_Information        1 non-null      object \n",
      " 11  Title                      30 non-null     object \n",
      " 12  Alternate_Titles           30 non-null     object \n",
      " 13  Date_of_Production         30 non-null     object \n",
      " 14  Location_Venue             30 non-null     object \n",
      " 15  Language_Note              3 non-null      object \n",
      " 16  Main_Production_Credits    30 non-null     object \n",
      " 17  Worktypes                  30 non-null     object \n",
      " 18  Performance_Genres         3 non-null      object \n",
      " 19  Summary                    30 non-null     object \n",
      " 20  Subjects_653               30 non-null     object \n",
      " 21  Rights_Holder              30 non-null     object \n",
      " 22  Broadcast_Note             0 non-null      object \n",
      " 23  Note_to_Cataloger          0 non-null      object \n",
      " 24  Pattern                    3 non-null      float64\n",
      " 25  Subjects_650               0 non-null      float64\n",
      " 26  Participants               30 non-null     object \n",
      " 27  Artist_Bio                 27 non-null     object \n",
      " 28  Language_List              27 non-null     object \n",
      " 29  Copyright_Contact          27 non-null     object \n",
      "dtypes: float64(2), object(28)\n",
      "memory usage: 7.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_combined_dmd = pd.concat([df_pre_2019_dmd,df_post_2019_dmd],ignore_index=True,keys=['pre', 'post'])\n",
    "#print(df_combined_dmd)\n",
    "print(df_combined_dmd.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_dmd = df_combined_dmd[[\"NOID\",\"Alternate_Titles\",\"Artist_Bio\",\"Copyright_Contact\",\"Date_of_Production\",\"Format\",\"HI\",\"Language_List\",\"Language_Note\",\"Location_Venue\",\"Main_Production_Credits\",\"Meeting_Information\",\"Participants\",\"Publication_Cycle\",\"Rights_Holder\",\"Run_Time\",\"Series_Title\",\"Subjects_650\",\"Subjects_653\",\"Summary\",\"Title\",\"Worktypes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_dmd.to_csv(\"hidvl_metadata_combined_%s.csv\"%filetime, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end!\n",
    "\n",
    "_Some ideas for improvement: split legacy summary column into summary and bio (currently doing this in OpenRefine)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
